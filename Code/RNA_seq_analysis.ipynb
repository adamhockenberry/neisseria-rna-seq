{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of RNA-seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `.ipynb` file should be placed in a directory titled `Code/`. \n",
    "\n",
    "In addition, one step *above* the `Code/` directory should be directories titled `Data/` and `Results/` such that file writing implemented here runs smoothly. \n",
    "\n",
    "So it doesn't matter where you put this directory, as long as the structure looks something like:\n",
    "\n",
    "    my_cool_project/Code/\n",
    "        RNA_seq_analysis.ipynb\n",
    "        sequencing_analysis_library.py\n",
    "\n",
    "    my_cool_project/Data/\n",
    "\n",
    "    my_cool_project/Results/\n",
    "    \n",
    "In addition, in either your global path (if you don't know what this is fret not) OR your `my_cool_project/Code/` directory you will need to have `sequencing_analysis_library.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common imports / necessary helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamhockenberry/.pyenv/versions/anaconda3-2.0.1/lib/python3.4/site-packages/matplotlib/__init__.py:878: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "#Common imports\n",
    "from Bio import SeqIO\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "#My helper library for this analysis\n",
    "import sequencing_analysis_library as SAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the genome ... choose wisely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genome_file = '/Users/adamhockenberry/Projects/Neisseria/Data/Genomes/fa1090.gb'\n",
    "# genome_file = '/Users/adamhockenberry/Projects/Neisseria/Code/temp_new_fa1090.gb'\n",
    "genome = list(SeqIO.parse(genome_file, 'genbank'))[0]\n",
    "organism = 'Neisseria'\n",
    "\n",
    "# genome_file = '/Users/adamhockenberry/Projects/Neisseria/Data/Genomes/na1000.gb'\n",
    "# genome = list(SeqIO.parse(genome_file, 'genbank'))[0]\n",
    "# organism = 'Caulobacter'\n",
    "\n",
    "genome_features_dict = SAL.get_genome_features(genome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read TSS predator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infile = '/Users/adamhockenberry/Downloads/TSSpredator_v1-04/04_01_16_NORPKM_more_sensitive/MasterTable.tsv'\n",
    "tss_df = pd.read_csv(infile, sep='\\t')\n",
    "tss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "control_tss_dict = {}\n",
    "treatment_tss_dict = {}\n",
    "for index in tss_df.index[:]:\n",
    "    if tss_df.iloc[index]['Genome'] == 'Normal':\n",
    "        if tss_df.iloc[index]['detected'] == 1:\n",
    "            location = tss_df.iloc[index]['SuperPos']\n",
    "            if tss_df.iloc[index]['SuperStrand'] == '+':\n",
    "                strand = 'plus'\n",
    "            elif tss_df.iloc[index]['SuperStrand'] == '-':\n",
    "                strand = 'minus'\n",
    "            else:\n",
    "                print('Error in strand')\n",
    "            control_tss_dict[index] = (strand, location, location)\n",
    "    \n",
    "    elif tss_df.iloc[index]['Genome'] == 'Oxidative':\n",
    "        if tss_df.iloc[index]['detected'] == 1:\n",
    "            location = tss_df.iloc[index]['SuperPos']\n",
    "            if tss_df.iloc[index]['SuperStrand'] == '+':\n",
    "                strand = 'plus'\n",
    "            elif tss_df.iloc[index]['SuperStrand'] == '-':\n",
    "                strand = 'minus'\n",
    "            else:\n",
    "                print('Error in strand')\n",
    "            treatment_tss_dict[index] = (strand, location, location)\n",
    "    else:\n",
    "        print('Error in genome')\n",
    "print(len(control_tss_dict.keys()), len(treatment_tss_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize data for individual genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "fwd_wiggle = '../Data/Neisseria/SQ-(1,3,5)_20_100_normed_f.wig'\n",
    "rev_wiggle = '../Data/Neisseria/SQ-(1,3,5)_20_100_normed_r.wig'\n",
    "fwd_dicty_ctrl, rev_dicty_ctrl =\\\n",
    "        SAL.read_single_wiggle(fwd_wiggle, rev_wiggle)\n",
    "\n",
    "# ###################    \n",
    "# fwd_wiggle = '../Data/Neisseria/SQ-(2,4,6)_20_100_normed_f.wig'\n",
    "# rev_wiggle = '../Data/Neisseria/SQ-(2,4,6)_20_100_normed_r.wig'\n",
    "# fwd_dicty_treatment, rev_dicty_treatment =\\\n",
    "#         SAL.read_single_wiggle(fwd_wiggle, rev_wiggle)\n",
    "\n",
    "# ###################    \n",
    "# fwd_wiggle = '../Data/Neisseria/SQ-(7,9,11)_20_100_normed_f.wig'\n",
    "# rev_wiggle = '../Data/Neisseria/SQ-(7,9,11)_20_100_normed_r.wig'\n",
    "# fwd_dicty_ctrl_drna, rev_dicty_ctrl_drna =\\\n",
    "#         SAL.read_single_wiggle(fwd_wiggle, rev_wiggle)\n",
    "\n",
    "# ###################    \n",
    "# fwd_wiggle = '../Data/Neisseria/SQ-(10,12)_20_100_normed_f.wig'\n",
    "# rev_wiggle = '../Data/Neisseria/SQ-(10,12)_20_100_normed_r.wig'\n",
    "# fwd_dicty_treatment_drna, rev_dicty_treatment_drna =\\\n",
    "#         SAL.read_single_wiggle(fwd_wiggle, rev_wiggle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_name = 'NGO0108'\n",
    "# NGO1767 (catalase) \n",
    "# NGO1055\n",
    "# NGO0114\n",
    "# NGO0108\n",
    "bases_to_add = 100\n",
    "window_beg, window_end = (int(genome_features_dict[feature_name].location.start), int(genome_features_dict[feature_name].location.end))\n",
    "vert_lines=[]\n",
    "window_beg = window_beg-bases_to_add\n",
    "window_end = window_end+bases_to_add\n",
    "defined_ylimits = False\n",
    "save_file = True\n",
    "SAL.plot_individual_segment(window_beg, window_end, [genome_features_dict[feature_name]],\\\n",
    "                            [('Control', fwd_dicty_ctrl_drna, rev_dicty_ctrl_drna), ('Treatment', fwd_dicty_treatment_drna, rev_dicty_treatment_drna)],\\\n",
    "                            defined_ylimits=defined_ylimits, vert_lines=vert_lines, feature_name=feature_name, save_file=save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bases_to_add = 100\n",
    "vert_lines=[]\n",
    "defined_ylimits = False\n",
    "save_file = False\n",
    "\n",
    "\n",
    "for feature_name in list(genome_features_dict)[:]:\n",
    "    window_beg, window_end = (int(genome_features_dict[feature_name].location.start), int(genome_features_dict[feature_name].location.end))\n",
    "    window_beg = window_beg-bases_to_add\n",
    "    window_end = window_end+bases_to_add\n",
    "    SAL.plot_individual_segment(window_beg, window_end, [genome_features_dict[feature_name]],\\\n",
    "                                [('Ctrl', fwd_dicty_ctrl, rev_dicty_ctrl), ('H202', fwd_dicty_treatment, rev_dicty_treatment)],\\\n",
    "                                defined_ylimits=defined_ylimits, vert_lines=vert_lines, feature_name=feature_name, save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about un-annotated genes?\n",
    "The above analysis relied entirely on the published, annotated genome sequences. An interesting part of RNA-seq analysis is that perhaps we can find novel unannotated transcripts or sRNAs.\n",
    "\n",
    "To do so, we'll have to at this stage brute force it. I recommend scanning in window of ~10,000 bps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment Vs Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "window_beg, window_end = (50000, 60000)\n",
    "# defined_ylimits = (5000, 5000)\n",
    "# defined_ylimits = (200, 200)\n",
    "# defined_ylimits = (20, 20)\n",
    "defined_ylimits = False\n",
    "\n",
    "feature_list = SAL.get_features_in_window(genome_features_dict, window_beg, window_end)\n",
    "\n",
    "# vert_lines=[('minus', 2037736, 2038032)]\n",
    "vert_lines=[]\n",
    "\n",
    "\n",
    "feature_name=False\n",
    "save_file=False\n",
    "SAL.plot_individual_segment(window_beg, window_end, feature_list,\\\n",
    "                                [('Control', fwd_dicty_ctrl, rev_dicty_ctrl), ('Treatment', fwd_dicty_treatment, rev_dicty_treatment)],\\\n",
    "                                defined_ylimits=defined_ylimits, vert_lines=vert_lines, feature_name=feature_name,\\\n",
    "                            save_file=save_file)\n",
    "\n",
    "feature_list.sort(key=lambda x: x.location.start)\n",
    "print('Features shown on plot:')\n",
    "print('Plus strand:')\n",
    "for feature in feature_list:\n",
    "    if feature.strand == 1:\n",
    "        print(feature.qualifiers['locus_tag'][0], feature.location.start, feature.location.end)\n",
    "print('Minus strand:')\n",
    "for feature in feature_list:\n",
    "    if feature.strand == -1:\n",
    "        print(feature.qualifiers['locus_tag'][0], feature.location.start, feature.location.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tex treatment, control and treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_beg, window_end = (50000, 60000)\n",
    "# defined_ylimits = (5000, 5000)\n",
    "# defined_ylimits = (2000, 2000)\n",
    "# defined_ylimits = (200, 200)\n",
    "defined_ylimits = False\n",
    "logy = False\n",
    "\n",
    "feature_list = SAL.get_features_in_window(genome_features_dict, window_beg, window_end)\n",
    "\n",
    "vert_lines_control = []\n",
    "for i in control_tss_dict.values():\n",
    "    if i[1] > window_beg and i[1] < window_end:\n",
    "        vert_lines_control.append(i)\n",
    "vert_lines_treatment = []\n",
    "for i in treatment_tss_dict.values():\n",
    "    if i[1] > window_beg and i[1] < window_end:\n",
    "        vert_lines_treatment.append(i)\n",
    "\n",
    "feature_name='NoRPKM_more_sensitive_control'\n",
    "save_file=True\n",
    "\n",
    "\n",
    "SAL.plot_individual_segment(window_beg, window_end, feature_list,\\\n",
    "                                [('Control', fwd_dicty_ctrl, rev_dicty_ctrl), ('Tex-Control', fwd_dicty_ctrl_drna, rev_dicty_ctrl_drna)],\\\n",
    "                                defined_ylimits=defined_ylimits, logy=logy, vert_lines=vert_lines_control, feature_name=feature_name,\\\n",
    "                            save_file=save_file)\n",
    "\n",
    "feature_name='NoRPKM_more_sensitive_h202'\n",
    "SAL.plot_individual_segment(window_beg, window_end, feature_list,\\\n",
    "                                [('h2o2', fwd_dicty_treatment, rev_dicty_treatment), ('Tex-h202', fwd_dicty_treatment_drna, rev_dicty_treatment_drna)],\\\n",
    "                                defined_ylimits=defined_ylimits, logy=logy, vert_lines=vert_lines_treatment, feature_name=feature_name,\\\n",
    "                            save_file=save_file)\n",
    "\n",
    "###To show the feature names\n",
    "feature_list.sort(key=lambda x: x.location.start)\n",
    "print('Features shown on plot:')\n",
    "print('Plus strand:')\n",
    "for feature in feature_list:\n",
    "    if feature.strand == 1:\n",
    "        print(feature.qualifiers['locus_tag'][0], feature.location.start, feature.location.end)\n",
    "print('Minus strand:')\n",
    "for feature in feature_list:\n",
    "    if feature.strand == -1:\n",
    "        print(feature.qualifiers['locus_tag'][0], feature.location.start, feature.location.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of hypothetical sRNAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_file = False\n",
    "defined_ylimits=False\n",
    "\n",
    "srna_file = open('../Data/candidate_srna_neisseria.txt', 'r')\n",
    "counter = 0\n",
    "for line in srna_file:\n",
    "    counter += 1\n",
    "    if counter > 20:\n",
    "        break\n",
    "    split_line = line.split('|')\n",
    "    try:\n",
    "        name = split_line[0].split()[0]\n",
    "        direction = split_line[2].split()[2]\n",
    "        beg = int(split_line[2].split()[0])\n",
    "        end = int(split_line[2].split()[1])\n",
    "        print(name, direction, beg, end)\n",
    "        SAL.plot_individual_segment(beg, end, [],\\\n",
    "                                [('Control', fwd_dicty_ctrl, rev_dicty_ctrl), ('Treatment', fwd_dicty_treatment, rev_dicty_treatment)],\\\n",
    "                                defined_ylimits=defined_ylimits, feature_name=name+' '+direction, save_file=save_file)\n",
    "    except IndexError:\n",
    "        print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of much higher quality sRNAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_file = False\n",
    "defined_ylimits=False\n",
    "srna_df = pd.read_csv('../Data/short_candidate_srna_neisseria.csv', delimiter=',',\\\n",
    "                        names=['Name', 'Beginning', 'End', 'Strand'] )\n",
    "srna_df\n",
    "for index,row in srna_df.iterrows():\n",
    "    print(row['Name'])\n",
    "    if row['Strand']=='+':\n",
    "        strand = 'plus'\n",
    "    if row['Strand']=='-':\n",
    "        strand = 'minus'\n",
    "    vert_lines= (strand, row['Beginning'], row['End'])\n",
    "    window_beg = row['Beginning']-500\n",
    "    window_end = row['End']+500\n",
    "    feature_list = []\n",
    "    for feature in feature_dict.values():\n",
    "        if feature.location.start > window_beg and feature.location.start < window_end:\n",
    "            feature_list.append(feature)\n",
    "        elif feature.location.end > window_beg and feature.location.end < window_end:\n",
    "            feature_list.append(feature)\n",
    "        elif feature.location.start < window_beg and feature.location.end > window_end:\n",
    "            feature_list.append(feature)\n",
    "    SAL.plot_individual_segment(window_beg, window_end, feature_list,\\\n",
    "                            [('Control', fwd_dicty_ctrl, rev_dicty_ctrl), ('Treatment', fwd_dicty_treatment, rev_dicty_treatment)],\\\n",
    "                            defined_ylimits=defined_ylimits, vert_lines=vert_lines, feature_name=row['Name']+' '+row['Strand'], save_file=save_file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(genome.seq[5720:6320].reverse_complement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist([float(i) for i in tss_df['enrichmentFactor']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blah = []\n",
    "for i in tss_df['enrichmentFactor']:\n",
    "    try:\n",
    "        tempy = float(i)\n",
    "        if np.isnan(tempy) == False:\n",
    "            blah.append(tempy)\n",
    "    except ValueError:\n",
    "        pass\n",
    "print(len(blah))\n",
    "plt.figure()\n",
    "plt.hist(blah, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kallisto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiggle_dicty_no_tex = {}\n",
    "for number in [1, 2, 3, 4, 5, 6]:\n",
    "    wiggle_dicty_no_tex[number] = {}\n",
    "    fwd_wiggle = '/Users/adamhockenberry/workspace/kallisto/neisseria_04_22_16/SQ{}normed{}.wig'.format(number, '_f')\n",
    "    rev_wiggle = '/Users/adamhockenberry/workspace/kallisto/neisseria_04_22_16/SQ{}normed{}.wig'.format(number, '_r')\n",
    "    fwd_dicty, rev_dicty = SAL.read_single_wiggle(fwd_wiggle, rev_wiggle)\n",
    "    wiggle_dicty_no_tex[number]['Fwd'] = fwd_dicty\n",
    "    wiggle_dicty_no_tex[number]['Rev'] = rev_dicty\n",
    "\n",
    "wiggle_dicty_tex = {}\n",
    "for number in [7, 8, 9, 10, 11, 12]:\n",
    "    wiggle_dicty_tex[number] = {}\n",
    "    fwd_wiggle = '/Users/adamhockenberry/workspace/kallisto/neisseria_04_22_16/SQ{}normed{}.wig'.format(number, '_f')\n",
    "    rev_wiggle = '/Users/adamhockenberry/workspace/kallisto/neisseria_04_22_16/SQ{}normed{}.wig'.format(number, '_r')\n",
    "    fwd_dicty, rev_dicty = SAL.read_single_wiggle(fwd_wiggle, rev_wiggle)\n",
    "    wiggle_dicty_tex[number]['Fwd'] = fwd_dicty\n",
    "    wiggle_dicty_tex[number]['Rev'] = rev_dicty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctrl_dicty_no_tex = {}\n",
    "samples = [1, 3, 5]\n",
    "for strand in ['Fwd', 'Rev']:\n",
    "    ctrl_dicty_no_tex[strand] = {}\n",
    "    for i in range(len(genome.seq)):\n",
    "        tempy = []\n",
    "        for sample in samples:\n",
    "            try:\n",
    "                tempy.append(wiggle_dicty_no_tex[sample][strand][i])\n",
    "            except KeyError:\n",
    "                tempy.append(0)\n",
    "        ctrl_dicty_no_tex[strand][i] = np.mean(tempy)\n",
    "        \n",
    "treatment_dicty_no_tex = {}\n",
    "samples = [2, 4, 6]\n",
    "for strand in ['Fwd', 'Rev']:\n",
    "    treatment_dicty_no_tex[strand] = {}\n",
    "    for i in range(len(genome.seq)):\n",
    "        tempy = []\n",
    "        for sample in samples:\n",
    "            try:\n",
    "                tempy.append(wiggle_dicty_no_tex[sample][strand][i])\n",
    "            except KeyError:\n",
    "                tempy.append(0)\n",
    "        treatment_dicty_no_tex[strand][i] = np.mean(tempy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coverage_dict = {}\n",
    "for key, feature in genome_features_dict.items():\n",
    "    sequencing_coverage = []\n",
    "    if feature.type == 'gene':\n",
    "        if feature.strand == 1:\n",
    "            for i in range(int(feature.location.start), int(feature.location.end)):\n",
    "                sequencing_coverage.append(ctrl_dicty_no_tex['Fwd'][i])\n",
    "            coverage_dict[feature.qualifiers['locus_tag'][0]] = sequencing_coverage\n",
    "        elif feature.strand == -1:\n",
    "            for i in range(int(feature.location.start), int(feature.location.end)):\n",
    "                    sequencing_coverage.append(ctrl_dicty_no_tex['Rev'][i])\n",
    "            coverage_dict[feature.qualifiers['locus_tag'][0]] = sequencing_coverage[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../temp_coverage_dict.json', 'w') as outfile:\n",
    "    json.dump(coverage_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctrl_dicty_tex = {}\n",
    "samples = [7, 9, 11]\n",
    "for strand in ['Fwd', 'Rev']:\n",
    "    ctrl_dicty_tex[strand] = {}\n",
    "    for i in range(len(genome.seq)):\n",
    "        tempy = []\n",
    "        for sample in samples:\n",
    "            try:\n",
    "                tempy.append(wiggle_dicty_tex[sample][strand][i])\n",
    "            except KeyError:\n",
    "                tempy.append(0)\n",
    "        ctrl_dicty_tex[strand][i] = np.mean(tempy)\n",
    "        \n",
    "treatment_dicty_tex = {}\n",
    "samples = [10, 12]\n",
    "for strand in ['Fwd', 'Rev']:\n",
    "    treatment_dicty_tex[strand] = {}\n",
    "    for i in range(len(genome.seq)):\n",
    "        tempy = []\n",
    "        for sample in samples:\n",
    "            try:\n",
    "                tempy.append(wiggle_dicty_tex[sample][strand][i])\n",
    "            except KeyError:\n",
    "                tempy.append(0)\n",
    "        treatment_dicty_tex[strand][i] = np.mean(tempy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "window_beg, window_end = (531770-100, 532720+100)\n",
    "# window_beg, window_end = (1014597-100, 1015079+100)\n",
    "# defined_ylimits = (5000, 5000)\n",
    "# defined_ylimits = (2000, 2000)\n",
    "# defined_ylimits = (200, 200)\n",
    "defined_ylimits = False\n",
    "logy = False\n",
    "\n",
    "feature_list = SAL.get_features_in_window(genome_features_dict, window_beg, window_end)\n",
    "\n",
    "feature_name=''\n",
    "save_file=True\n",
    "# feature_name = 'NGO1055 (-TEX)'\n",
    "feature_name = 'NGO0554'\n",
    "\n",
    "SAL.plot_individual_segment(window_beg, window_end, feature_list,\\\n",
    "                                [('+ TEX / - H2O2', ctrl_dicty_tex['Fwd'], ctrl_dicty_tex['Rev'], 'r'),\\\n",
    "                                ('- TEX / - H2O2', ctrl_dicty_no_tex['Fwd'], ctrl_dicty_no_tex['Rev'], 'b'),\\\n",
    "                                ('+ TEX / + H2O2', treatment_dicty_tex['Fwd'], treatment_dicty_tex['Rev'], 'm'),\\\n",
    "                                ('- TEX / + H2O2', treatment_dicty_no_tex['Fwd'], treatment_dicty_no_tex['Rev'], 'c')],\\\n",
    "                                defined_ylimits=defined_ylimits, logy=logy, vert_lines='', feature_name=feature_name,\\\n",
    "                            save_file=save_file)\n",
    "\n",
    "# # feature_name = 'NGO1055 (+TEX)'\n",
    "# feature_name = 'NGO0554 (+H2O2)'\n",
    "\n",
    "# SAL.plot_individual_segment(window_beg, window_end, feature_list,\\\n",
    "#                                 [('+ TEX', treatment_dicty_tex['Fwd'], treatment_dicty_tex['Rev'], 'm'),\\\n",
    "#                                 ('- TEX', treatment_dicty_no_tex['Fwd'], treatment_dicty_no_tex['Rev'], 'c')],\\\n",
    "#                                 defined_ylimits=defined_ylimits, logy=logy, vert_lines='', feature_name=feature_name,\\\n",
    "#                             save_file=save_file)\n",
    "\n",
    "# for i in [1, 3, 5, 4, 6]:\n",
    "#     fwd_dicty = wiggle_dicty_no_tex[i]['Fwd']\n",
    "#     rev_dicty = wiggle_dicty_no_tex[i]['Rev']\n",
    "#     SAL.plot_individual_segment(window_beg, window_end, feature_list,\\\n",
    "#                                     [('Control', fwd_dicty, rev_dicty)],\\\n",
    "#                                     defined_ylimits=defined_ylimits, logy=logy, vert_lines='', feature_name=feature_name,\\\n",
    "#                                 save_file=save_file)\n",
    "\n",
    "# for i in [7, 9, 11, 10, 12]:\n",
    "#     fwd_dicty = wiggle_dicty_tex[i]['Fwd']\n",
    "#     rev_dicty = wiggle_dicty_tex[i]['Rev']\n",
    "#     SAL.plot_individual_segment(window_beg, window_end, feature_list,\\\n",
    "#                                     [('Control', fwd_dicty, rev_dicty)],\\\n",
    "#                                     defined_ylimits=defined_ylimits, logy=logy, vert_lines='', feature_name=feature_name,\\\n",
    "#                                 save_file=save_file)\n",
    "\n",
    "# ###To show the feature names\n",
    "feature_list.sort(key=lambda x: x.location.start)\n",
    "print('Features shown on plot:')\n",
    "print('Plus strand:')\n",
    "for feature in feature_list:\n",
    "    if feature.strand == 1:\n",
    "        print(feature.qualifiers['locus_tag'][0], feature.location.start, feature.location.end)\n",
    "print('Minus strand:')\n",
    "for feature in feature_list:\n",
    "    if feature.strand == -1:\n",
    "        print(feature.qualifiers['locus_tag'][0], feature.location.start, feature.location.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctrl_dicty_no_tex['Fwd'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genome_file = '/Users/adamhockenberry/Projects/Neisseria/Data/Genomes/fa1090.gb'\n",
    "genome_old = list(SeqIO.parse(genome_file, 'genbank'))[0]\n",
    "organism = 'Neisseria'\n",
    "genome_features_dict_old = SAL.get_genome_features(genome_old)\n",
    "\n",
    "genome_file = '/Users/adamhockenberry/Projects/Neisseria/Code/temp_new_fa1090.gb'\n",
    "genome_new = list(SeqIO.parse(genome_file, 'genbank'))[0]\n",
    "organism = 'Neisseria'\n",
    "genome_features_dict_new = SAL.get_genome_features(genome_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "found = 0\n",
    "not_found = 0\n",
    "for new_feature in genome_features_dict_new:\n",
    "    temp_start = []\n",
    "    temp_stop = []\n",
    "    for old_feature in genome_features_dict_old:\n",
    "        if genome_features_dict_new[new_feature].location.start == genome_features_dict_old[old_feature].location.start:\n",
    "            temp_start.append(old_feature)\n",
    "        if genome_features_dict_new[new_feature].location.end == genome_features_dict_old[old_feature].location.end:\n",
    "            temp_stop.append(old_feature)\n",
    "    if len(temp_start) == 1 and len(temp_stop) == 1 and temp_start == temp_stop: \n",
    "        data[new_feature] = (temp_start[0], 'Perfect')        \n",
    "        \n",
    "    elif len(temp_start) == 1 and len(temp_stop) == 0:\n",
    "        data[new_feature] = (temp_start[0], 'Same start different stop')        \n",
    "\n",
    "    elif len(temp_start) == 0 and len(temp_stop) == 1:\n",
    "        data[new_feature] = (temp_stop[0], 'Same stop different start')\n",
    "        \n",
    "    elif len(temp_start) == 0 and len(temp_stop) == 0:\n",
    "        data[new_feature] = ('NA', 'NA')\n",
    "    else:\n",
    "        print(new_feature, temp_start, temp_stop)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame()\n",
    "df_new = df_new.from_dict(data,orient='index')\n",
    "df_new = df_new.sort_index()\n",
    "df_new.columns = ['Old ID', 'Note']\n",
    "\n",
    "df_new.to_excel('new_to_old_annotation.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(genome_features_dict_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genome_features_dict_new['XNG0995'].location.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
